{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f752a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchPapersMetadataOutput(BaseModel):\n",
    "    summary: str = Field(\n",
    "        ...,\n",
    "        description=\"\"\"\n",
    "        Summarize the research paper in a concise, yet technical manner. Always include relevant details about the technical implementation (if available). \n",
    "\n",
    "        Please return the summary as short one line description of the paper.\n",
    "        \n",
    "        Examples of summaries to illustrate how I want them to look like:\n",
    "        - The paper critiques traditional industry approaches and offers a refined, audience-specific definition of explainability. Its influence lies in the structured visual taxonomies and conceptual frameworks it provides across model types - making it a foundational reference for ongoing XAI research.\n",
    "\n",
    "        - The paper tracks the evolution of face recognition, from shallow to deep methods, identifying key technical advancements through network architectures, loss functions and data processing/augmentation techniques.\n",
    "\n",
    "        - The paper surveys the shift from traditional face recognition methods to deep learning approaches that achieve state-of-the-art performance across complex scenarios. Its influence stems from a systematic categorization of network architectures and a comprehensive taxonomy.\n",
    "\n",
    "        - BLOOM is an open-access response to proprietary, English-centric language models developed by a small pool of tech companies. The model's training data spans academic texts, local news sources, community contributions, and low-resource languages.\n",
    "       \"\"\"\n",
    "    )  \n",
    "    paper_type: str = Field(\n",
    "        ...,\n",
    "        description=\"\"\"\n",
    "        What is the paper's core function or intent?\n",
    "        Select one of the following:\n",
    "        - Technical Innovation/Methodological Proposal\n",
    "        - Benchmark/Empirical Evaluation\n",
    "        - Literature Review\n",
    "        - Survey/Taxonomy\n",
    "        - Conceptual/Theoretical Discussion\n",
    "        - Engineering/Systems Description\n",
    "        - Case Study/Application Report\n",
    "        - Dataset Release\n",
    "        - Tool/Library Introduction\n",
    "        - Other\n",
    "        \"\"\"\n",
    "    )\n",
    "    application_domain: str = Field(\n",
    "        ...,\n",
    "        description=\"\"\"\n",
    "        What domain or field is the research applied to?\n",
    "        Note: Use \"Multilingual/Cross-Lingual NLP\" when the paper's primary focus is on models, datasets, or evaluation across multiple languages, or transfer between languages.\n",
    "        If the paper addresses language tasks in a single language context (e.g., English sentiment classification), select \"NLP\" instead.\n",
    "        Note: If the paper focuses on the autonomous coordination of tasks, tools, or decisions by a goal-directed system, classify it under AI Agents/Agent-Based Systems.\n",
    "        If it focuses on generating, repairing, or synthesizing code, classify it under Code Generation/Software Engineering in Application Domain or Code Generation in Research Theme if it's the technical focus.\n",
    "         \n",
    "        Select one of the following:\n",
    "        - Natural Language Processing (NLP)\n",
    "        - Multilingual/Cross-Lingual NLP\n",
    "        - Computer Vision\n",
    "        - Time Series/Forecasting\n",
    "        - Multimodal (e.g., vision-language)\n",
    "        - Robotics/Control\n",
    "        - Recommender Systems\n",
    "        - Financial Modelling/Risk Analysis\n",
    "        - Scientific Discovery\n",
    "        - Healthcare/Biomedicine\n",
    "        - Knowledge Management/Retrieval\n",
    "        - Document Processing\n",
    "        - Automation/Workflow Optimization\n",
    "        - Social/Ethical Implications\n",
    "        - General-Purpose/Domain-Agnostic\n",
    "        - Code Generation/Software Engineering\n",
    "        - AI Agents/Agent-Based Systems\n",
    "        - Other\n",
    "        \"\"\"\n",
    "    )\n",
    "    method: str = Field(\n",
    "        ...,\n",
    "        description=\"\"\"\n",
    "        Which machine learning paradigm or model class is used?\n",
    "\n",
    "        Select one of the following:\n",
    "        - Transformer-based Models\n",
    "        - Graph Neural Networks\n",
    "        - Convolutional Neural Networks\n",
    "        - Recurrent Neural Networks\n",
    "        - Probabilistic Models/Bayesian Inference\n",
    "        - Evolutionary Algorithms/Heuristics\n",
    "        - Reinforcement Learning (RL)\n",
    "        - RLHF (Reinforcement Learning from Human Feedback)\n",
    "        - Generative Models (e.g., GANs, VAEs, Diffusion)\n",
    "        - Symbolic/Logic-based Systems\n",
    "        - Retrieval-Augmented Generation (RAG)\n",
    "        - Foundation Models/Large Language Models\n",
    "        - Unsupervised Learning (e.g., clustering, dimensionality reduction)\n",
    "        - Supervised Learning (e.g., classification, regression)\n",
    "        - Other\n",
    "        \"\"\"\n",
    "    )\n",
    "    purpose: str = Field(\n",
    "        ...,\n",
    "        description=\"\"\"\n",
    "        What is the primary aim of the paper's research effort?\n",
    "\n",
    "        Select one of the following:\n",
    "        - Model Benchmarking/Performance Comparison\n",
    "        - Scaling Law Analysis\n",
    "        - Training Efficiency/Optimization\n",
    "        - Model Capabilities/Theory-Led Innovation\n",
    "        - Interpretability/Explainability\n",
    "        - Fairness/Bias Analysis\n",
    "        - Robustness/Adversarial Evaluation\n",
    "        - Human-AI Interaction\n",
    "        - Model Risk/Governance\n",
    "        - Prompt Engineering/Instruction Tuning\n",
    "        - Other\n",
    "        \"\"\"\n",
    "    )\n",
    "    model_stage_focus: str = Field(\n",
    "        ...,\n",
    "        description=\"\"\"\n",
    "        What part of the AI pipeline does the paper focus on?\n",
    "\n",
    "        Select one of the following:\n",
    "        - Model Architecture/Design\n",
    "        - Training Algorithms/Objectives\n",
    "        - Fine-Tuning/Adaptation\n",
    "        - Inference Optimization\n",
    "        - Evaluation/Metrics\n",
    "        - Deployment/Integration\n",
    "        - Other\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "    research_main_theme: str = Field(\n",
    "        ...,\n",
    "        description=\"\"\"\n",
    "        What is the paper's most relevant technical theme?\n",
    "        \n",
    "        Select one of the following:\n",
    "        - Model Architecture Based Efficiency\n",
    "        - Training Strategies\n",
    "        - Novel Model Architectures\n",
    "        - Evaluation & Robustness\n",
    "        - Infrastructure & Deployment\n",
    "        - Governance & Policy\n",
    "        - Reasoning & Emerging Behavior\n",
    "        \"\"\"\n",
    "    )\n",
    "    research_sub_theme: str = Field(\n",
    "        ...,\n",
    "        description=\"\"\"\n",
    "        What is the paper's most relevant sub-technical theme based on the main theme selected?\n",
    "\n",
    "        If no sub-theme fits, use Other (explain)\n",
    "        Note: Use the Other (explain)\n",
    "        \n",
    "        Select one of the sub-themes under the main categories below or other:\n",
    "        Model Architecture Based Efficiency:\n",
    "        - Sparse Attention/Efficient Attention\n",
    "        - Low-Rank Adaptation (LoRA)/Weight-Decomposed Low-Rank Adaptation (DoRA)\n",
    "        - Quantization/Pruning\n",
    "        - Mixture of Experts (MoE)\n",
    "        - Neural Architecture Search (NAS)\n",
    "        \n",
    "        \n",
    "        Training Strategies:\n",
    "        - Instruction Tuning/Preference Modelling\n",
    "        - Policy Gradient Methods\n",
    "        - Contrastive Learning\n",
    "        - Self-Supervised Learning\n",
    "        - Meta-Learning\n",
    "        - Knowledge Distillation\n",
    "        - Curriculum Learning\n",
    "        - Few-Shot/Zero-Shot Learning\n",
    "        - Regularizers/Schedulers\n",
    "        \n",
    "        \n",
    "        Novel Model Architectures:\n",
    "        - Vision Transformers\n",
    "        - Mamba\n",
    "        - ResNet\n",
    "        - Perceiver IO\n",
    "        - Diffusion Transformers\n",
    "        - Gated CNNs\n",
    "        \n",
    "        \n",
    "        Evaluation & Robustness:\n",
    "        - Explainability/Interpretability\n",
    "        - Adversarial Robustness\n",
    "        - Calibration/Uncertainty Quantification\n",
    "        - Algorithmic Fairness\n",
    "        - Evaluation Frameworks/Benchmarks\n",
    "        \n",
    "        \n",
    "        Infrastructure & Deployment:\n",
    "        - Compiler Optimizations (e.g., XLA, TVM)\n",
    "        - Hardware-Aware Training/Inference\n",
    "        - Federated Learning Systems\n",
    "        - Edge/On-Device Deployment\n",
    "        - Model Compression\n",
    "        - Data-Centric Research\n",
    "        - Synthetic Data Generation\n",
    "        - Data Augmentation Strategies\n",
    "        - Label Noise/Quality Analysis\n",
    "        - Active Learning/Human-in-the-Loop\n",
    "        - Semi-Supervised Data Strategies\n",
    "        \n",
    "        \n",
    "        Governance & Policy:\n",
    "        - Responsible AI Governance\n",
    "        - AI Alignment\n",
    "        - Catastrophic AI Risk\n",
    "        - Auditing/Red Teaming\n",
    "        - Regulatory Compliance/Standardization\n",
    "        \n",
    "        \n",
    "        Reasoning & Emerging Behavior:\n",
    "        - Multimodal Reasoning\n",
    "        - Chain-of-Thought Reasoning\n",
    "        - Emergent Behaviors in LLMs\n",
    "        - Tool Use/Programmatic Reasoning\n",
    "        - Long-Horizon Planning\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "research_papers_prompt = \"\"\"\n",
    "You are an expert research assistant tasked with classifying AI research papers. These papers are written by authors affiliated with financial services, but you must not assume that their subject matter is related to financial services.You are classifying the core research contribution, not its institutional origin or setting.\n",
    "Your goal is to assign one label per category based on the technical content of each paper, using the predefined taxonomy below. Please return your output in a JSON format. \n",
    "\n",
    "General Instructions:\n",
    "- Assign only one label per category.\n",
    "- Do not use \"Other\" unless the paper clearly falls outside all listed categories or spans multiple equally without a dominant focus. However, do not 'force fit' the paper into a category if it doesn't meaningfully apply.\n",
    "- If multiple labels seem appropriate, choose the one most emphasized in the abstract or framed as the paper's novel contribution.\n",
    "- 'Scene setting' or background context does not necessarily indicate the main technical focus.\n",
    "- If you select \"Other\" in any category, include a brief rationale. Avoid using \"Other\" in more than one category unless absolutely necessary - and justify each use separately.\n",
    "- Consider cross-category dependencies: e.g., if the paper introduces a novel architecture like ResNet, the method should likely correspond to Convolutional Neural Networks.\n",
    "- Some foundational or general-purpose papers may not map neatly to a single domain. In those cases, choose General-Purpose/Domain-Agnostic under Application Domain.\n",
    "- For Research Theme, return both the Main Theme and the Sub-theme in the format:\n",
    " Main Theme → Sub-theme\n",
    " If no sub-theme fits, write:\n",
    " Main Theme → Other (explain)\n",
    "\n",
    "Summary:\n",
    "\n",
    "Please return the summary as short one line description of the paper.\n",
    "        \n",
    "        Examples of summaries to illustrate how I want them to look like:\n",
    "        - The paper critiques traditional industry approaches and offers a refined, audience-specific definition of explainability. Its influence lies in the structured visual taxonomies and conceptual frameworks it provides across model types - making it a foundational reference for ongoing XAI research.\n",
    "\n",
    "        - The paper tracks the evolution of face recognition, from shallow to deep methods, identifying key technical advancements through network architectures, loss functions and data processing/augmentation techniques.\n",
    "\n",
    "        - The paper surveys the shift from traditional face recognition methods to deep learning approaches that achieve state-of-the-art performance across complex scenarios. Its influence stems from a systematic categorization of network architectures and a comprehensive taxonomy.\n",
    "\n",
    "        - BLOOM is an open-access response to proprietary, English-centric language models developed by a small pool of tech companies. The model's training data spans academic texts, local news sources, community contributions, and low-resource languages.\n",
    "\n",
    "Classification Categories:\n",
    "\n",
    "Paper Type:\n",
    "What is the paper's core function or intent?\n",
    "- Technical Innovation/Methodological Proposal\n",
    "- Benchmark/Empirical Evaluation\n",
    "- Literature Review\n",
    "- Survey/Taxonomy\n",
    "- Conceptual/Theoretical Discussion\n",
    "- Engineering/Systems Description\n",
    "- Case Study/Application Report\n",
    "- Dataset Release\n",
    "- Tool/Library Introduction\n",
    "- Other\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99f8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types, errors\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import overload, Union\n",
    "\n",
    "\n",
    "# name of the gemini model we are using\n",
    "model_name = \"google/gemini-2.5-flash\"\n",
    "\n",
    "# gemini client and configuration\n",
    "google_genai_client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"evident-data-dev\",\n",
    "    location=\"europe-west1\",\n",
    ")\n",
    "\n",
    "# setup the model\n",
    "model_configuration = types.GenerateContentConfig(\n",
    "    system_instruction=research_papers_prompt,\n",
    "    response_mime_type=\"application/json\",\n",
    "    response_schema=ResearchPapersMetadataOutput,\n",
    ")\n",
    "\n",
    "def classify_dataframe(text_df: pd.DataFrame, text_column: str, identifiable_column: str):\n",
    "        \"\"\"\n",
    "        Takes a pandas DataFrame of potential use cases and\n",
    "        dds the required metadata so it can be added to the use case tracker\n",
    "        Args:\n",
    "            text_df (pd.DataFrame): press releases\n",
    "            text_column str: name of the column containing the body of text to use\n",
    "        Returns:\n",
    "            A pandas DataFrame containing the LLM JSON output as columns\n",
    "        \"\"\"\n",
    "        classification_list = []\n",
    "        for i in range(len(text_df)):\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(\"Waiting 1min 30s\")\n",
    "                time.sleep(90)\n",
    "            try:\n",
    "                response = google_genai_client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    config=model_configuration,\n",
    "                    contents=user_prompt.format(text=text_df[text_column].iloc[i]),\n",
    "                )\n",
    "            except errors.APIError as e:\n",
    "                raise ValueError(f\"Code:{e.code}\", \"\\n\", f\"Message: {e.message}\")\n",
    "                \n",
    "            classification_list.append([i,\n",
    "                                        text_df[identifiable_column].iloc[i],\n",
    "                                        text_df[text_column].iloc[i],\n",
    "                                        response.parsed.summary,\n",
    "                                        response.parsed.paper_type,\n",
    "                                        response.parsed.application_domain,\n",
    "                                        response.parsed.method,\n",
    "                                        response.parsed.purpose,\n",
    "                                        response.parsed.model_stage_focus,\n",
    "                                        response.parsed.research_main_theme,\n",
    "                                        response.parsed.research_sub_theme\n",
    "                                        ])\n",
    "            \n",
    "            if (i + 1) % 50 == 0 or (i + 1) == len(text_df):\n",
    "                print(f\"Progress: {(i + 1) / len(text_df):.2%}\")\n",
    "        \n",
    "        return pd.DataFrame(classification_list, columns=[\n",
    "            \"index\",\n",
    "            identifiable_column,\n",
    "            \"body\",\n",
    "            \"summary\",\n",
    "            \"paper_type\",\n",
    "            \"application_domain\",\n",
    "            \"method\",\n",
    "            \"purpose\",\n",
    "            \"model_stage_focus\",\n",
    "            \"research_main_theme\",\n",
    "            \"research_sub_theme\"\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e972dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
